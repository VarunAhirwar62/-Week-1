# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os


# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session
from tensorflow import keras
import tensorflow
import tensorflow as tf
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout,BatchNormalization,GlobalAveragePooling2D,Dropout,GlobalMaxPooling2D
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model
from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.applications.mobilenet import preprocess_input
from tensorflow.keras.applications import Xception,NASNetMobile,DenseNet201
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.xception import preprocess_input, decode_predictions
from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.regularizers import l2
from tensorflow.keras.layers import Layer, MultiHeadAttention
from tensorflow.keras.layers import LayerNormalization
from tensorflow.keras.models import Sequential
import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
from glob import glob
2024-04-01 08:49:59.821678: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-01 08:49:59.821782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-01 08:49:59.943293: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import plot_model
train_path="/kaggle/input/the-wildfire-dataset/the_wildfire_dataset_2n_version/train"
test_path="/kaggle/input/the-wildfire-dataset/the_wildfire_dataset_2n_version/test"
val_path="/kaggle/input/the-wildfire-dataset/the_wildfire_dataset_2n_version/val"
train_datagen = ImageDataGenerator( 
                                   rescale=1./255,
                                   rotation_range=20,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                   #brightness_range=[0.5, 1.5],
                                  ) 
test_datagen = ImageDataGenerator(rescale = 1./255)
val_datagen = ImageDataGenerator(  rescale=1./255.0)
training_set = train_datagen.flow_from_directory(train_path,
                                                 target_size = (224,224),
                                                 batch_size = 64,
                                                 class_mode = 'binary')
test_set = test_datagen.flow_from_directory(test_path,
                                            target_size = (224,224),
                                            batch_size = 64,
                                            class_mode = 'binary',
                                            shuffle=False)
val_set = val_datagen.flow_from_directory(val_path,
                                            target_size = (224,224),
                                            batch_size = 64,
                                            class_mode = 'binary')
Found 1887 images belonging to 2 classes.
Found 410 images belonging to 2 classes.
Found 402 images belonging to 2 classes.
base_model = MobileNet(input_shape=(224,224,3),weights='imagenet', include_top=False)
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5
17225924/17225924 ━━━━━━━━━━━━━━━━━━━━ 2s 0us/step
for layer in base_model.layers:
  layer.trainable=False
x = base_model.output
x = Flatten()(x)
x = Dense(1024, activation="relu")(x)
x = Dropout(0.2)(x)
x = BatchNormalization()(x)
x = Dense(256, activation="relu")(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.2)(x)
x = BatchNormalization()(x)
x = Dense(64, activation="relu")(x)
x = Dropout(0.2)(x)
x = BatchNormalization()(x)
predictions = Dense(2, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)
from keras.losses import SparseCategoricalCrossentropy

# Instantiate the loss function
loss_fn = SparseCategoricalCrossentropy()
model.compile(optimizer='adam', loss=loss_fn,
              metrics=['accuracy'])
history = model.fit(
    training_set,
    epochs=50,
    validation_data=val_set,
    #callbacks=[callbacks]
)
Epoch 1/50
/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
 1/30 ━━━━━━━━━━━━━━━━━━━━ 1:11:54 149s/step - accuracy: 0.5938 - loss: 0.9417
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1711961584.687597      89 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
W0000 00:00:1711961584.716818      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update
 2/30 ━━━━━━━━━━━━━━━━━━━━ 1:30 3s/step - accuracy: 0.5898 - loss: 0.9822     
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (104688771 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
14/30 ━━━━━━━━━━━━━━━━━━━━ 4:25 17s/step - accuracy: 0.6357 - loss: 0.8381
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (89747104 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
30/30 ━━━━━━━━━━━━━━━━━━━━ 0s 12s/step - accuracy: 0.6610 - loss: 0.7677 
W0000 00:00:1711961984.490063      90 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update
30/30 ━━━━━━━━━━━━━━━━━━━━ 636s 17s/step - accuracy: 0.6622 - loss: 0.7647 - val_accuracy: 0.8109 - val_loss: 0.6489
Epoch 2/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 460s 12s/step - accuracy: 0.7730 - loss: 0.5257 - val_accuracy: 0.8284 - val_loss: 0.4460
Epoch 3/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 486s 13s/step - accuracy: 0.7865 - loss: 0.4535 - val_accuracy: 0.8433 - val_loss: 0.4515
Epoch 4/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 463s 12s/step - accuracy: 0.8235 - loss: 0.3968 - val_accuracy: 0.8557 - val_loss: 0.3672
Epoch 5/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 485s 13s/step - accuracy: 0.8505 - loss: 0.3402 - val_accuracy: 0.8408 - val_loss: 0.4916
Epoch 6/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 471s 13s/step - accuracy: 0.8533 - loss: 0.3401 - val_accuracy: 0.8259 - val_loss: 0.4685
Epoch 7/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 467s 12s/step - accuracy: 0.8643 - loss: 0.3098 - val_accuracy: 0.8308 - val_loss: 0.4590
Epoch 8/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 493s 13s/step - accuracy: 0.8779 - loss: 0.3136 - val_accuracy: 0.8607 - val_loss: 0.3774
Epoch 9/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 478s 13s/step - accuracy: 0.8936 - loss: 0.2449 - val_accuracy: 0.8433 - val_loss: 0.3754
Epoch 10/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 481s 13s/step - accuracy: 0.8695 - loss: 0.2718 - val_accuracy: 0.8433 - val_loss: 0.3754
Epoch 11/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 511s 14s/step - accuracy: 0.8699 - loss: 0.2950 - val_accuracy: 0.8582 - val_loss: 0.3669
Epoch 12/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 486s 13s/step - accuracy: 0.8864 - loss: 0.2659 - val_accuracy: 0.8507 - val_loss: 0.3655
Epoch 13/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 458s 12s/step - accuracy: 0.8809 - loss: 0.2685 - val_accuracy: 0.8756 - val_loss: 0.3119
Epoch 14/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 459s 12s/step - accuracy: 0.8988 - loss: 0.2431 - val_accuracy: 0.8557 - val_loss: 0.3672
Epoch 15/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 482s 13s/step - accuracy: 0.8854 - loss: 0.2552 - val_accuracy: 0.8308 - val_loss: 0.5059
Epoch 16/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 504s 14s/step - accuracy: 0.9030 - loss: 0.2287 - val_accuracy: 0.8458 - val_loss: 0.4530
Epoch 17/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 487s 13s/step - accuracy: 0.8973 - loss: 0.2236 - val_accuracy: 0.8532 - val_loss: 0.4655
Epoch 18/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 476s 13s/step - accuracy: 0.9105 - loss: 0.2233 - val_accuracy: 0.8706 - val_loss: 0.3476
Epoch 19/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 495s 13s/step - accuracy: 0.9231 - loss: 0.1912 - val_accuracy: 0.8706 - val_loss: 0.3142
Epoch 20/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 478s 13s/step - accuracy: 0.9156 - loss: 0.2050 - val_accuracy: 0.8632 - val_loss: 0.4455
Epoch 21/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 467s 13s/step - accuracy: 0.9073 - loss: 0.2219 - val_accuracy: 0.8706 - val_loss: 0.3865
Epoch 22/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 476s 13s/step - accuracy: 0.9055 - loss: 0.2269 - val_accuracy: 0.8781 - val_loss: 0.3004
Epoch 23/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 496s 13s/step - accuracy: 0.9079 - loss: 0.2250 - val_accuracy: 0.8831 - val_loss: 0.3336
Epoch 24/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 482s 13s/step - accuracy: 0.9065 - loss: 0.2241 - val_accuracy: 0.8806 - val_loss: 0.3572
Epoch 25/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 502s 13s/step - accuracy: 0.9215 - loss: 0.2105 - val_accuracy: 0.8458 - val_loss: 0.4244
Epoch 26/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 530s 12s/step - accuracy: 0.9278 - loss: 0.1999 - val_accuracy: 0.8856 - val_loss: 0.3013
Epoch 27/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 464s 12s/step - accuracy: 0.9145 - loss: 0.1868 - val_accuracy: 0.8333 - val_loss: 0.4506
Epoch 28/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 493s 13s/step - accuracy: 0.9304 - loss: 0.1832 - val_accuracy: 0.8806 - val_loss: 0.3830
Epoch 29/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 481s 13s/step - accuracy: 0.9196 - loss: 0.1850 - val_accuracy: 0.8905 - val_loss: 0.3239
Epoch 30/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 455s 12s/step - accuracy: 0.9217 - loss: 0.2068 - val_accuracy: 0.8682 - val_loss: 0.3546
Epoch 31/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 489s 13s/step - accuracy: 0.9211 - loss: 0.1768 - val_accuracy: 0.8582 - val_loss: 0.3641
Epoch 32/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 454s 12s/step - accuracy: 0.9190 - loss: 0.1783 - val_accuracy: 0.8831 - val_loss: 0.3303
Epoch 33/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 508s 14s/step - accuracy: 0.9366 - loss: 0.1638 - val_accuracy: 0.8806 - val_loss: 0.3401
Epoch 34/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 473s 13s/step - accuracy: 0.9258 - loss: 0.1715 - val_accuracy: 0.8856 - val_loss: 0.3156
Epoch 35/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 477s 13s/step - accuracy: 0.9273 - loss: 0.1717 - val_accuracy: 0.8706 - val_loss: 0.3533
Epoch 36/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 485s 13s/step - accuracy: 0.9452 - loss: 0.1425 - val_accuracy: 0.8607 - val_loss: 0.3419
Epoch 37/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 486s 13s/step - accuracy: 0.9252 - loss: 0.1931 - val_accuracy: 0.8856 - val_loss: 0.3210
Epoch 38/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 505s 14s/step - accuracy: 0.9398 - loss: 0.1645 - val_accuracy: 0.8632 - val_loss: 0.3827
Epoch 39/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 490s 13s/step - accuracy: 0.9284 - loss: 0.1694 - val_accuracy: 0.8781 - val_loss: 0.3935
Epoch 40/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 457s 12s/step - accuracy: 0.9433 - loss: 0.1571 - val_accuracy: 0.8532 - val_loss: 0.4583
Epoch 41/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 510s 14s/step - accuracy: 0.9410 - loss: 0.1453 - val_accuracy: 0.8706 - val_loss: 0.3679
Epoch 42/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 488s 13s/step - accuracy: 0.9342 - loss: 0.1619 - val_accuracy: 0.8557 - val_loss: 0.3892
Epoch 43/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 487s 13s/step - accuracy: 0.9374 - loss: 0.1690 - val_accuracy: 0.8682 - val_loss: 0.4020
Epoch 44/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 496s 13s/step - accuracy: 0.9386 - loss: 0.1570 - val_accuracy: 0.8781 - val_loss: 0.4078
Epoch 45/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 495s 13s/step - accuracy: 0.9277 - loss: 0.1757 - val_accuracy: 0.8657 - val_loss: 0.3771
Epoch 46/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 459s 12s/step - accuracy: 0.9384 - loss: 0.1576 - val_accuracy: 0.8507 - val_loss: 0.3908
Epoch 47/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 495s 13s/step - accuracy: 0.9257 - loss: 0.1776 - val_accuracy: 0.8657 - val_loss: 0.3475
Epoch 48/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 463s 12s/step - accuracy: 0.9435 - loss: 0.1516 - val_accuracy: 0.8607 - val_loss: 0.4169
Epoch 49/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 508s 13s/step - accuracy: 0.9420 - loss: 0.1437 - val_accuracy: 0.8607 - val_loss: 0.4093
Epoch 50/50
30/30 ━━━━━━━━━━━━━━━━━━━━ 497s 13s/step - accuracy: 0.9343 - loss: 0.1666 - val_accuracy: 0.8383 - val_loss: 0.4719
model.evaluate(test_set)
2/7 ━━━━━━━━━━━━━━━━━━━━ 1:05 13s/step - accuracy: 0.6758 - loss: 0.8185
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
3/7 ━━━━━━━━━━━━━━━━━━━━ 1:03 16s/step - accuracy: 0.6988 - loss: 0.7968
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
7/7 ━━━━━━━━━━━━━━━━━━━━ 121s 18s/step - accuracy: 0.7968 - loss: 0.5582
[0.33120760321617126, 0.8780487775802612]
import matplotlib.pyplot as plt

# Plot accuracy and loss side by side
plt.figure(figsize=(12, 5))  # Adjust the figure size as needed

# Accuracy subplot
plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Loss subplot
plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()  # Ensure the subplots do not overlap
plt.show()

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
import numpy as np

num_test_sample=len(test_set)
num_classes=len(test_set.class_indices)

predicted_probabilities=model.predict(test_set,steps=num_test_sample)
predicted_labels=np.argmax(predicted_probabilities,axis=1)

true_labels=test_set.classes

report=classification_report(true_labels,predicted_labels)
print(report)
1/7 ━━━━━━━━━━━━━━━━━━━━ 1:15 13s/step
W0000 00:00:1711985923.644476      91 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update
2/7 ━━━━━━━━━━━━━━━━━━━━ 27s 6s/step  
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
3/7 ━━━━━━━━━━━━━━━━━━━━ 38s 10s/step
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
7/7 ━━━━━━━━━━━━━━━━━━━━ 94s 14s/step
              precision    recall  f1-score   support

           0       0.98      0.70      0.82       159
           1       0.84      0.99      0.91       251

    accuracy                           0.88       410
   macro avg       0.91      0.85      0.86       410
weighted avg       0.89      0.88      0.87       410

import numpy as np
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Step 1: Make predictions on the test set
y_pred = model.predict(test_set)

# Assuming you have true labels for the test set
y_true = test_set.classes

# Step 2: Calculate ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_true, y_pred[:, 1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()
2/7 ━━━━━━━━━━━━━━━━━━━━ 37s 7s/step
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
3/7 ━━━━━━━━━━━━━━━━━━━━ 43s 11s/step
/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3176: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
7/7 ━━━━━━━━━━━━━━━━━━━━ 92s 14s/step

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Assuming you have the true labels (y_true) and predicted labels (predicted_labels)
# Compute the confusion matrix
cm = confusion_matrix(y_true, predicted_labels)

# Create a heatmap for visualization
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(ticks=[0, 1], labels=['Negative', 'Positive'])
plt.yticks(ticks=[0, 1], labels=['Negative', 'Positive'])
plt.show()

# Sensitivity and Specificity
tn, fp, fn, tp = cm.ravel()
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)

print(f"\nSensitivity: {sensitivity}")
print(f"Specificity: {specificity}")

# Precision, Recall, G-measure, F1 Score
precision = tp / (tp + fp)
recall = sensitivity  # same as sensitivity
f1_score = 2 * (precision * recall) / (precision + recall)
g_measure = 2 * ((precision * recall) / (precision + recall))

print(f"\nPrecision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1_score}")
print(f"G-measure: {g_measure}")
Sensitivity: 0.9920318725099602
Specificity: 0.6981132075471698
